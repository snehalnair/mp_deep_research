# Evaluation Report: MPDeepResearch_v1

**Generated:** 2026-02-05T22:38:24.077326

**Overall Score:** 0.121

---

## Summary

### Agent Performance

| Metric | Value |
|--------|-------|
| Task Completion Rate | 0.000 |
| Tool Selection Accuracy | 0.000 |
| Tool Usage Efficiency | 0.000 |
| Avg Tool Calls/Task | 4.8 |
| Avg Execution Time (s) | 11.0 |
| Error Rate | 1.000 |

### Discovery Benchmark by Difficulty

| Difficulty | Score |
|------------|-------|
| easy | 0.000 |
| medium | 0.000 |
| hard | 0.000 |

### Reasoning Quality (LLM-as-Judge)

| Dimension | Score (1-5) |
|-----------|-------------|
| scientific_accuracy | 4.20 |
| reasoning_coherence | 4.00 |
| appropriate_uncertainty | 3.80 |
| completeness | 4.10 |

### Confidence Intervals (95%)

| Metric | Lower | Upper |
|--------|-------|-------|
| overall_score | 0.060 | 0.060 |
